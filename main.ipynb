{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.applications import EfficientNetB3\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_graph(h, accType, name):\n",
    "    plt.plot(h.history[accType])\n",
    "    plt.plot(h.history[\"val_\" + accType])\n",
    "    plt.title(\"model accuracy\")\n",
    "    plt.ylabel(accType)\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "    fig = plt.gcf()\n",
    "    name = \"graphs/\" + name + \".png\"\n",
    "    fig.savefig(name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def create_bar(labels):\n",
    "    sorted_dict = dict(sorted(labels.items()))\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    years = sorted_dict.keys()\n",
    "    frequency = sorted_dict.values()\n",
    "    ax.set_xticks(np.arange(-5, 20))\n",
    "    ax.bar(years,frequency)\n",
    "    plt.title(\"Label distribution\")\n",
    "    plt.ylabel(\"Number of images\")\n",
    "    plt.xlabel(\"Class\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset\n",
    "dataset = dataset.Dataset(\"rawData/images/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_bar(dataset.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH = 'data/'\n",
    "IMG_SIZE = 224 \n",
    "SIZE = (IMG_SIZE, IMG_SIZE)\n",
    "BATCH_SIZE = 32\n",
    "LABELS = dataset.getLabelList()\n",
    "# change labels = LABELS for regression\n",
    "# change labels = \"inferred\" for classification\n",
    "(train_set, test_set) = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATAPATH,\n",
    "    image_size = SIZE,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    labels = \"inferred\",\n",
    "    label_mode = 'int',\n",
    "    color_mode = 'rgb',\n",
    "    validation_split = 0.2,\n",
    "    subset = 'both',\n",
    "    seed = 1234,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Krizhevsky_Datapath = 'data/'\n",
    "Krizhevsky_Size = (224, 224)\n",
    "\n",
    "(krizhevsky_train_set, krizhevsky_test_set) = tf.keras.utils.image_dataset_from_directory(\n",
    "    Krizhevsky_Datapath,\n",
    "    image_size = Krizhevsky_Size,\n",
    "    batch_size = 128,\n",
    "    labels = \"inferred\",\n",
    "    label_mode = 'int',\n",
    "    color_mode = 'rgb',\n",
    "    validation_split = 0.2,\n",
    "    subset = 'both',\n",
    "    seed = 1234,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_set.class_names)\n",
    "num_classes = len(train_set.class_names)\n",
    "num_classes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EfficientNetB3 with Sparse Categorical Crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "augmentation = keras.Sequential([layers.RandomRotation(0.1), layers.RandomBrightness(0.1), layers.RandomContrast(0.1)])\n",
    "\n",
    "with strategy.scope():\n",
    "    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    augmented = augmentation(inputs)\n",
    "    efficientnet = EfficientNetB3(include_top=False, input_tensor=augmented, weights=\"imagenet\")\n",
    "    pooling = layers.GlobalAveragePooling2D()(efficientnet.output)\n",
    "    batch_norm = layers.BatchNormalization()(pooling)\n",
    "    dropout = layers.Dropout(0.2)(batch_norm)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(dropout)\n",
    "    modelEfficientNet = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    modelEfficientNet.compile(\n",
    "        optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EfficientNetB3 with Sparse Categorical Crossentropy with dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "augmentation = keras.Sequential([layers.RandomRotation(0.1), layers.RandomBrightness(0.1), layers.RandomContrast(0.1)])\n",
    "\n",
    "with strategy.scope():\n",
    "    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    augmented = augmentation(inputs)\n",
    "    efficientnet = EfficientNetB3(include_top=False, input_tensor=augmented, weights=\"imagenet\")\n",
    "    pooling = layers.GlobalAveragePooling2D()(efficientnet.output)\n",
    "    batch_norm = layers.BatchNormalization()(pooling)\n",
    "    dropout = layers.Dropout(0.2)(batch_norm)\n",
    "    layer3 = layers.Dense(units = 512, activation='relu')(dropout)\n",
    "    layer2 = layers.Dense(units = 256, activation='relu')(layer3)\n",
    "    layer1 = layers.Dense(units = 128, activation='relu')(layer2)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(layer1)\n",
    "    modelEfficientNetConnected = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    modelEfficientNetConnected.compile(\n",
    "        optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EfficientNetB3 with Sparse Categorical Crossentropy with dense layers and dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "augmentation = keras.Sequential([layers.RandomRotation(0.1), layers.RandomBrightness(0.1), layers.RandomContrast(0.1)])\n",
    "\n",
    "with strategy.scope():\n",
    "    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    augmented = augmentation(inputs)\n",
    "    efficientnet = EfficientNetB3(include_top=False, input_tensor=augmented, weights=\"imagenet\")\n",
    "    pooling = layers.GlobalAveragePooling2D()(efficientnet.output)\n",
    "    batch_norm = layers.BatchNormalization()(pooling)\n",
    "    dropout3 = layers.Dropout(0.2)(batch_norm)\n",
    "    layer3 = layers.Dense(units = 512, activation='relu')(dropout3)\n",
    "    dropout2 = layers.Dropout(0.2)(layer3)\n",
    "    layer2 = layers.Dense(units = 256, activation='relu')(dropout2)\n",
    "    dropout1 = layers.Dropout(0.2)(layer2)\n",
    "    layer1 = layers.Dense(units = 128, activation='relu')(dropout1)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(layer1)\n",
    "    modelEfficientNetConnectedDropout = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    modelEfficientNetConnectedDropout.compile(\n",
    "        optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EfficientNet3 with Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "augmentation = keras.Sequential([layers.RandomRotation(0.1), layers.RandomBrightness(0.1), layers.RandomContrast(0.1)])\n",
    "\n",
    "with strategy.scope():\n",
    "    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    augmented = augmentation(inputs)\n",
    "    efficientnet = EfficientNetB3(include_top=False, input_tensor=inputs, weights=\"imagenet\")\n",
    "    pooling = layers.GlobalAveragePooling2D()(efficientnet.output)\n",
    "    batch_norm = layers.BatchNormalization()(pooling)\n",
    "    dropout3 = layers.Dropout(0.2)(batch_norm)\n",
    "    layer3 = layers.Dense(units = 256, activation='relu')(dropout3)\n",
    "    dropout2 = layers.Dropout(0.2)(layer3)\n",
    "    layer2 = layers.Dense(units = 128, activation='relu')(dropout2)\n",
    "    dropout1 = layers.Dropout(0.2)(layer2)\n",
    "    layer1 = layers.Dense(units = 64, activation='relu')(dropout1)\n",
    "    outputs = layers.Dense(units = 1)(layer1)\n",
    "    modelEfficientNet = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    modelEfficientNet.compile(\n",
    "        optimizer=optimizer, loss=\"mean_absolute_error\", metrics=[\"mean_absolute_error\"]\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EfficientNetB3 with MAE, larger fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "augmentation = keras.Sequential([layers.RandomRotation(0.1), layers.RandomBrightness(0.1), layers.RandomContrast(0.1)])\n",
    "\n",
    "with strategy.scope():\n",
    "    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    augmented = augmentation(inputs)\n",
    "    efficientnet = EfficientNetB3(include_top=False, input_tensor=inputs, weights=\"imagenet\")\n",
    "    pooling = layers.GlobalAveragePooling2D()(efficientnet.output)\n",
    "    batch_norm = layers.BatchNormalization()(pooling)\n",
    "    dropout = layers.Dropout(0.2)(batch_norm)\n",
    "    layer3 = layers.Dense(units = 512, activation='relu')(dropout)\n",
    "    layer2 = layers.Dense(units = 256, activation='relu')(layer3)\n",
    "    layer1 = layers.Dense(units = 64, activation='relu')(layer2)\n",
    "    outputs = layers.Dense(units = 1)(layer1)\n",
    "    modelEfficientNet = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    modelEfficientNet.compile(\n",
    "        optimizer=optimizer, loss=\"mean_absolute_error\", metrics=[\"mean_absolute_error\"]\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model from [this](https://datascience.stackexchange.com/questions/106600/how-to-perform-regression-on-image-data-using-tensorflow) StackOverflow post. <br>\n",
    "This uses a regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_layer = tf.keras.Sequential([                                    \n",
    "    tf.keras.layers.RandomRotation(0.1),\n",
    "    tf.keras.layers.RandomContrast(0.1),\n",
    "    tf.keras.layers.RandomBrightness(0.1)\n",
    "], name='data_augmentation')  \n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    augmentation_layer,\n",
    "    tf.keras.layers.Conv2D(3, 3, activation='relu'),\n",
    "    tf.keras.layers.Conv2D(3, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2),\n",
    "    tf.keras.layers.Conv2D(3, 3, activation='relu'),\n",
    "    tf.keras.layers.Conv2D(3, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2),\n",
    "    tf.keras.layers.Conv2D(3, 3, activation='relu'),\n",
    "    tf.keras.layers.Conv2D(3, 3, activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=512, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=256, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])\n",
    "\n",
    "model.compile(loss='mean_absolute_error', optimizer=\"adam\", metrics=['mean_absolute_error'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network from [This](https://papers.nips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf) paper _without_ multi GPU: <br>\n",
    "5 Conv layers followed by 3 fully connected layers. Afer each fully connected layer, a ReLu unit is used as nonlinearity. Additionally normalization and dropout are applied \n",
    "(found via [Image Orientation Estimation with Convolutional Networks](https://lmb.informatik.uni-freiburg.de/Publications/2015/FDB15/image_orientation.pdf)). <br>\n",
    "**Not Implemented**: \n",
    "- Multiple GPUs\n",
    "- First Layers with Stride of 4\n",
    "\n",
    "Other hyper parameters to change: \n",
    "- Batch size of 128\n",
    "- 90 cycles through the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [ tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=5)] # Paper does not specify the patience, so I chose 5\n",
    "optimizer = tf.keras.optimizers.experimental.SGD(weight_decay=0.0005, learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "one_bias_initializer = tf.keras.initializers.Constant(value=1)\n",
    "zero_bias_initializer = tf.keras.initializers.Constant(value=0)\n",
    "\n",
    "KrizhevskyModel = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(5, 5, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01, seed=None), bias_initializer=zero_bias_initializer),\n",
    "    tf.keras.layers.Lambda(lambda input: tf.nn.local_response_normalization(input=input, alpha=0.0001, beta=0.75, depth_radius=5, bias=2.0)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(3, 3, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01, seed=None), bias_initializer=one_bias_initializer),\n",
    "    tf.keras.layers.Lambda(lambda input: tf.nn.local_response_normalization(input=input, alpha=0.0001, beta=0.75, depth_radius=5, bias=2.0)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(3, 3, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01, seed=None), bias_initializer=zero_bias_initializer),\n",
    "    tf.keras.layers.Conv2D(3, 3, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01, seed=None), bias_initializer=one_bias_initializer),\n",
    "    tf.keras.layers.Conv2D(3, 3, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01, seed=None), bias_initializer=one_bias_initializer),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=4096, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01, seed=None), bias_initializer=one_bias_initializer),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(units=4096, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01, seed=None), bias_initializer=one_bias_initializer),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(units=num_classes, activation='softmax', kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.01, seed=None), bias_initializer=one_bias_initializer),\n",
    "])\n",
    "\n",
    "KrizhevskyModel.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histEfficientNet = modelEfficientNet.fit(train_set, epochs=EPOCHS, validation_data=test_set) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(histEfficientNet, \"mean_absolute_error\", \"EfficientNetB3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histEfficientNetConnected = modelEfficientNetConnected.fit(train_set, epochs=EPOCHS, validation_data=test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(histEfficientNetConnected, \"accuracy\", \"EfficientNetB3Connected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histEfficientNetConnectedDropout = modelEfficientNetConnectedDropout.fit(train_set, epochs=EPOCHS, validation_data=test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(histEfficientNetConnectedDropout, \"accuracy\", \"EfficientNetB3ConnectedDropout\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histModel = model.fit(train_set, epochs=EPOCHS, validation_data=test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(histModel, \"mean_absolute_error\", \"Model1\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Krizhevsky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histKrizhevsky = KrizhevskyModel.fit(train_set, epochs=90, validation_data=test_set, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(histKrizhevsky, \"accuracy\", \"Krizhevsky\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AutoKeras from [this](https://autokeras.com/tutorial/image_regression/) tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autokeras as ak\n",
    "\n",
    "reg = ak.ImageRegressor(overwrite=True, max_trials=5, loss=\"mean_absolute_error\", metrics=[\"mean_absolute_error\"])\n",
    "reg.fit(train_set, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
